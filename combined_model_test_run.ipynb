{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "combined_model_test_run.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1oNBMd764RuO3xQWt_BwFGq0BgbvZ6FPp",
      "authorship_tag": "ABX9TyMpmZAoPY8riCiyFs8sqCIQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IverMartinsen/ColabNotebooks/blob/main/combined_model_test_run.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSpD5OSCrKTZ"
      },
      "source": [
        "import sys\n",
        "\n",
        "sys.path.append('/content/drive/MyDrive/src/Python')\n",
        "\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from modules.stratified_idxs import stratified_idxs\n",
        "from modules.losses import MeanSquaredErrorKLD"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8-XeTupr-Jc"
      },
      "source": [
        "# Load dataframe of features\n",
        "df = pd.read_csv(\n",
        "    '/content/drive/MyDrive/Data/Grønlandskveiteotolitter/dataframe.csv')\n",
        "\n",
        "# Locate data with complete set of features\n",
        "notna = np.all(np.array(df.notna()), axis = 1)\n",
        "\n",
        "# Drop data with incomplete set of features\n",
        "df = df.dropna()\n",
        "\n",
        "# Create stratified indices for selecting datasets for training etc.\n",
        "train_idx, valid_idx, test_idx = stratified_idxs(\n",
        "    df['age'], (0.6, 0.2, 0.2), seed=123)\n",
        "\n",
        "# Create stratified subsets for training etc.\n",
        "df_train = df.iloc[train_idx]\n",
        "df_valid = df.iloc[valid_idx]\n",
        "df_test = df.iloc[test_idx]\n",
        "\n",
        "# Create utility functions\n",
        "df_features = lambda df: (\n",
        "    tf.convert_to_tensor(df['length']), tf.convert_to_tensor(df['sex'])) \n",
        "\n",
        "df_labels = lambda df: tf.convert_to_tensor(df['age'])\n",
        "\n",
        "labels = np.array(df['age'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trM3INUhrfBv"
      },
      "source": [
        "# Set constants\n",
        "image_size = (128, 128)\n",
        "batch_size = 32\n",
        "num_splits = 5\n",
        "\n",
        "file_path = '/content/drive/MyDrive/Data/Grønlandskveiteotolitter/greenland_halibut_std/'\n",
        "\n",
        "# Load images from directory in alphabetical order\n",
        "dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    file_path,\n",
        "    labels=None,\n",
        "    image_size=image_size,\n",
        "    shuffle=False)\n",
        "\n",
        "# Stack images into numpy array\n",
        "# Only use images with complete corresponding features\n",
        "images = np.stack(list(dataset.unbatch().as_numpy_iterator()))[notna]\n",
        "\n",
        "# List filenames\n",
        "filenames = np.array(tf.io.gfile.listdir(file_path + 'images/'))\n",
        "\n",
        "# training data\n",
        "x_tr = images[train_idx]\n",
        "y_tr = labels[train_idx]\n",
        "f_tr = list(filenames[train_idx])\n",
        "\n",
        "# validation data\n",
        "x_va = images[valid_idx]\n",
        "y_va = labels[valid_idx]\n",
        "f_va = list(filenames[valid_idx])\n",
        "\n",
        "# test data\n",
        "x_te = images[test_idx]\n",
        "y_te = labels[test_idx]\n",
        "f_te = list(filenames[test_idx])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZmqrebfjOic"
      },
      "source": [
        "# Create normalization layer for normalizing the numerical input.\n",
        "Normalization = tf.keras.layers.Normalization(None)\n",
        "# Fit normalization layer on training data\n",
        "Normalization.adapt(df_train['length'])\n",
        "\n",
        "# Create layer for mapping categorical labels to int\n",
        "Index = tf.keras.layers.StringLookup()\n",
        "# Fit index layer on training data\n",
        "Index.adapt(tf.constant(df_train['sex']))\n",
        "\n",
        "# Create layer for one-hot-encoding the categorical labels\n",
        "Encoding = tf.keras.layers.CategoryEncoding(\n",
        "    num_tokens=Index.vocabulary_size(), output_mode='one_hot')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_DzYITBjPtE"
      },
      "source": [
        "# Define model feature model\n",
        "num_input = tf.keras.Input(shape=(1,), name='length')\n",
        "cat_input = tf.keras.Input(shape=(1,), name='sex', dtype='string')\n",
        "\n",
        "mlp_inputs = [num_input, cat_input]\n",
        "features = tf.keras.layers.concatenate(\n",
        "    [Normalization(num_input), Encoding(Index(cat_input))])\n",
        "z = tf.keras.layers.Dense(8)(features)\n",
        "z = tf.keras.layers.BatchNormalization()(z)\n",
        "z = tf.keras.layers.ReLU()(z)\n",
        "mlp_outputs = tf.keras.layers.Dense(1, 'relu')(z)\n",
        "\n",
        "mlp = tf.keras.Model(mlp_inputs, mlp_outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cg1gAW-LjdmT"
      },
      "source": [
        "# Define pretrained base model without classification head\n",
        "base_model = tf.keras.applications.Xception(\n",
        "    input_shape=image_size + (3, ), \n",
        "    include_top=False,\n",
        "    pooling='avg')\n",
        "\n",
        "# Freeze all layers in base model\n",
        "#for layer in base_model.layers:\n",
        "#    layer.trainable=False\n",
        "\n",
        "# Define CNN. Note that by setting training=False in the base model\n",
        "# we always run the model in inference mode \n",
        "cnn_inputs = tf.keras.layers.Input(image_size + (3, ))\n",
        "x = tf.keras.applications.xception.preprocess_input(cnn_inputs)\n",
        "x = tf.keras.layers.RandomTranslation(0, 0.1)(x)\n",
        "x = tf.keras.layers.RandomRotation(0.1, fill_mode='constant')(x)\n",
        "x = base_model(cnn_inputs, training=False)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "cnn_outputs = tf.keras.layers.Dense(1, 'relu')(x)\n",
        "\n",
        "cnn = tf.keras.models.Model(cnn_inputs, cnn_outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvruA-HfkNpZ"
      },
      "source": [
        "# Define combined model\n",
        "combined = tf.keras.layers.concatenate([mlp.output, cnn.output])\n",
        "outputs = tf.keras.layers.Dense(1, 'relu')(combined)\n",
        "\n",
        "combined_model = tf.keras.Model([mlp.inputs, cnn.inputs], outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9ytkWmWn2ds"
      },
      "source": [
        "combined_model.compile(\n",
        "    tf.keras.optimizers.Adam(1e-3), \n",
        "    tf.keras.losses.MeanSquaredError())\n",
        "\n",
        "callbacks = tf.keras.callbacks.EarlyStopping(\n",
        "    patience=20, restore_best_weights=True)\n",
        "\n",
        "combined_model.fit([df_features(df_train), x_tr],\n",
        "                   y_tr,\n",
        "                   batch_size=32,\n",
        "                   epochs=100,\n",
        "                   validation_data=([df_features(df_valid), x_va], y_va),\n",
        "                   callbacks = callbacks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUlEiNQAEIA8"
      },
      "source": [
        "combined_model.evaluate(([df_features(df_test), x_te]), y_te)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYhBqNWlEjyX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFcyodGBCcwV"
      },
      "source": [
        "# Create layer for mapping categorical labels to int\n",
        "Index = tf.keras.layers.StringLookup()\n",
        "# Fit index layer on training data\n",
        "Index.adapt(tf.constant(df_train['sex']))\n",
        "\n",
        "#image_size = (128, 128)\n",
        "\n",
        "# Create layer for one-hot-encoding the categorical labels\n",
        "Encoding = tf.keras.layers.CategoryEncoding(\n",
        "    num_tokens=Index.vocabulary_size(), output_mode='one_hot')\n",
        "\n",
        "# Define pretrained base model without classification head\n",
        "base_model = tf.keras.applications.Xception(\n",
        "    input_shape=image_size + (3, ), \n",
        "    include_top=False,\n",
        "    pooling='avg')\n",
        "\n",
        "# Define CNN. Note that by setting training=False in the base model\n",
        "# we always run the model in inference mode \n",
        "cnn_input = tf.keras.layers.Input(image_size + (3, ))\n",
        "cat_input = tf.keras.Input(shape=(1,), name='gender', dtype='string')\n",
        "gender = Encoding(Index(cat_input))\n",
        "\n",
        "x = tf.keras.applications.xception.preprocess_input(cnn_input)\n",
        "x = tf.keras.layers.RandomTranslation(0, 0.1)(x)\n",
        "x = tf.keras.layers.RandomRotation(0.1, fill_mode='constant')(x)\n",
        "x = base_model(x, training=False)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "x = tf.keras.layers.Dense(3, 'relu')(x)\n",
        "outputs = tf.keras.layers.Dot(axes=1)([x, gender])\n",
        "\n",
        "cnn = tf.keras.models.Model([cat_input, cnn_input], tf.keras.layers.Concatenate()([outputs, gender]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RynR20KeaH19"
      },
      "source": [
        "def normal_divergence(mean1, mean2, sigma1, sigma2):\n",
        "\n",
        "    sigma2 = tf.cast(tf.constant(1, shape=sigma2.shape), sigma2.dtype)\n",
        "\n",
        "    div = tf.math.log(sigma2 / sigma1) + (sigma1 ** 2 + (mean1 - mean2) ** 2) / (2 * sigma2 ** 2) - 1 / 2\n",
        "    \n",
        "    return div\n",
        "    #return tf.where(tf.math.is_nan(div), div, tf.zeros_like(div))\n",
        "    #return tf.zeros_like(div)\n",
        "\n",
        "\n",
        "class MeanSquaredErrorKLD(tf.keras.losses.Loss):\n",
        "\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        \n",
        "        mask = y_pred[:, 2:]\n",
        "        tmp = tf.reshape(y_pred[:, 0], (-1, 1))\n",
        "        \n",
        "        _y_true = tf.cast(y_true*tf.cast(mask, y_true.dtype), tf.float64)\n",
        "        _y_pred = tf.cast(tmp*tf.cast(mask, tmp.dtype), tf.float64)\n",
        "        \n",
        "        n_true = tf.reduce_sum(tf.cast(_y_true != 0, _y_true.dtype), axis=0)\n",
        "        n_pred = tf.reduce_sum(tf.cast(_y_pred != 0, _y_pred.dtype), axis=0)\n",
        "\n",
        "        mean_true = tf.reduce_sum(_y_true, axis=0) / n_true\n",
        "        mean_pred = tf.reduce_sum(_y_pred, axis=0) / n_pred\n",
        "\n",
        "        std_true = tf.reduce_sum((_y_true - mean_true*tf.cast(mask, _y_true.dtype))**2, axis=0) / n_true\n",
        "        std_pred = tf.reduce_sum((_y_pred - mean_pred*tf.cast(mask, _y_true.dtype))**2, axis=0) / n_pred\n",
        "\n",
        "        gamma = tf.constant(1, dtype=tf.float64)\n",
        "\n",
        "        kld = gamma*tf.reduce_sum(normal_divergence(mean_true, mean_pred, std_true, std_pred))\n",
        "        \n",
        "        return tf.keras.losses.mean_squared_error(y_true, tmp) + tf.cast(kld, tf.float32)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "b_SJvLBoH_pM",
        "outputId": "85342cdb-1fee-4b33-dd26-40e6dcadc163"
      },
      "source": [
        "cnn.compile(\n",
        "    tf.keras.optimizers.Adam(1e-3), \n",
        "    MeanSquaredErrorKLD())\n",
        "\n",
        "callbacks = tf.keras.callbacks.EarlyStopping(\n",
        "    patience=20, restore_best_weights=True)\n",
        "\n",
        "cnn.fit([tf.convert_to_tensor(df_train['sex']), x_tr],\n",
        "                   y_tr,\n",
        "                   batch_size=32,\n",
        "                   epochs=100,\n",
        "                   validation_data=([tf.convert_to_tensor(df_valid['sex']), x_va], y_va),\n",
        "                   callbacks = callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "67/67 [==============================] - 37s 461ms/step - loss: 287.5089 - val_loss: 251.2334\n",
            "Epoch 2/100\n",
            "66/67 [============================>.] - ETA: 0s - loss: 259.1676"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-213-4864744beea4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m                    \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                    \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sex'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_va\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_va\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                    callbacks = callbacks)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1187\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    433\u001b[0m     \"\"\"\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    293\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    313\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1028\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1084\u001b[0m     \u001b[0;34m\"\"\"Updates the progbar.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1086\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_init_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1087\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m  \u001b[0;31m# One-indexed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_maybe_init_progbar\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m       \u001b[0;31m# step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m       self.stateful_metrics = self.stateful_metrics.union(\n\u001b[0;32m-> 1063\u001b[0;31m           set(m.name for m in self.model.metrics))\n\u001b[0m\u001b[1;32m   1064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mmetrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flatten_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m       \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metrics\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgQrSfvAAOtJ",
        "outputId": "0206c994-2526-4f6c-f560-a8036a10818b"
      },
      "source": [
        "tf.reshape(cnn([tf.convert_to_tensor(df_test['sex'].iloc[:10, ]), x_te[:10]])[:, 0], (-1, 1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
              "array([[12.236333 ],\n",
              "       [10.335702 ],\n",
              "       [12.2605095],\n",
              "       [12.243863 ],\n",
              "       [12.256292 ],\n",
              "       [10.328697 ],\n",
              "       [12.252926 ],\n",
              "       [10.331232 ],\n",
              "       [10.304781 ],\n",
              "       [12.256765 ]], dtype=float32)>"
            ]
          },
          "execution_count": 187,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6ZwKmKTWmsf",
        "outputId": "4a85655f-8e02-462e-9fdb-d068b4d1c580"
      },
      "source": [
        "y_te[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([14, 11, 12, 12, 16,  9, 13, 11,  4, 12])"
            ]
          },
          "execution_count": 189,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "lAY9KSR8SwV-",
        "outputId": "81fb822d-6283-44be-baa3-48c4e21efd3b"
      },
      "source": [
        "\n",
        "\n",
        "cnn.evaluate([tf.convert_to_tensor(df_test['sex'].iloc[idx]), x_te[idx]], y_te[idx])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-188-2d26014bf5e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sex'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_te\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_te\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'idx' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_PkVlAZYOhO"
      },
      "source": [
        "idx = np.where(df_test['sex'] == 'male')\n",
        "df_test['sex'].iloc[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1I6MSkd4Y0Fv"
      },
      "source": [
        "np.sum(np.abs(y_hat[idx] - y_te[idx]) == 0) / len(y_hat[idx])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMZPro0rS89g"
      },
      "source": [
        "y_hat = np.array(cnn.predict([tf.convert_to_tensor(df_test['sex']), x_te]).round()).reshape(-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMU8KgW3TG4m"
      },
      "source": [
        "cnn.save('/content/drive/MyDrive/Forberedende forsøk/testrun_5_xception')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQWnasMVVA_q"
      },
      "source": [
        "df = pd.DataFrame({'true_age': y_te, 'predicted_age': y_hat})\n",
        "df.to_csv('loss5.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}